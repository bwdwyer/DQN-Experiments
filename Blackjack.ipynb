{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "import gym\n",
    "import imageio\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import pyvirtualdisplay\n",
    "import tensorflow as tf\n",
    "from gym import spaces\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.agents.ppo import ppo_agent\n",
    "from tf_agents.drivers import py_driver\n",
    "from tf_agents.environments import FlattenObservationsWrapper\n",
    "from tf_agents.environments import ObservationFilterWrapper\n",
    "from tf_agents.environments import PyEnvironmentBaseWrapper\n",
    "from gym import ObservationWrapper\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.utils import common\n",
    "from tf_agents.utils.nest_utils import batch_nested_array"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T00:27:18.191590Z",
     "start_time": "2023-07-13T00:27:17.984281Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "outputs": [],
   "source": [
    "# Set up a virtual display for rendering OpenAI gym environments.\n",
    "display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T00:27:18.278760Z",
     "start_time": "2023-07-13T00:27:17.998644Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "outputs": [
    {
     "data": {
      "text/plain": "'2.12.0'"
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.version.VERSION"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T00:27:18.278994Z",
     "start_time": "2023-07-13T00:27:18.089342Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "outputs": [],
   "source": [
    "num_iterations = 20_000  # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 100  # @param {type:\"integer\"}\n",
    "collect_steps_per_iteration = 1  # @param {type:\"integer\"}\n",
    "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 64  # @param {type:\"integer\"}\n",
    "learning_rate = 5e-4  # 1e-3  # @param {type:\"number\"}\n",
    "log_interval = 1000  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
    "eval_interval = 5000  # @param {type:\"integer\"}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T00:27:18.279026Z",
     "start_time": "2023-07-13T00:27:18.089438Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Environment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "outputs": [],
   "source": [
    "class SimplifiedObservations(gym.ObservationWrapper):\n",
    "# class SimplifiedObservations(PyEnvironmentBaseWrapper):\n",
    "    def __int__(self, env):\n",
    "        print(f\"SimplifiedObservations\")\n",
    "        super().__init__(env)\n",
    "        self.observation_space = spaces.Discrete(45)\n",
    "        print(f\"Observation space: {self.observation_space}\")\n",
    "        raise Exception(f\"SimplifiedObservations\")\n",
    "\n",
    "    def observation(self, observation):\n",
    "        print(\"Observing\")\n",
    "        return observation[0] + observation[1] + observation[2]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T00:33:20.914133Z",
     "start_time": "2023-07-13T00:33:20.899441Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BoundedArraySpec(shape=(), dtype=dtype('int64'), name='observation/tuple_0', minimum=0, maximum=31), BoundedArraySpec(shape=(), dtype=dtype('int64'), name='observation/tuple_1', minimum=0, maximum=10), BoundedArraySpec(shape=(), dtype=dtype('int64'), name='observation/tuple_2', minimum=0, maximum=1))\n"
     ]
    }
   ],
   "source": [
    "env_name = 'Blackjack-v1'\n",
    "env = suite_gym.load(\n",
    "    env_name,\n",
    "    # env_wrappers=[SimplifiedObservations],\n",
    "    gym_env_wrappers=[SimplifiedObservations],\n",
    "    # env_wrappers=[FlattenObservationsWrapper],\n",
    ")\n",
    "print(env.observation_spec())\n",
    "\n",
    "# print(env.observation_spec().values())\n",
    "# env = FlattenObservationsWrapper(env)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T00:33:22.093944Z",
     "start_time": "2023-07-13T00:33:22.074482Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observing\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "If shallow structure is a sequence, input must also be a sequence. Input has type: <class 'int'>.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[327], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreset\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m PIL\u001B[38;5;241m.\u001B[39mImage\u001B[38;5;241m.\u001B[39mfromarray(env\u001B[38;5;241m.\u001B[39mrender())\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/tf_agents/environments/py_environment.py:195\u001B[0m, in \u001B[0;36mPyEnvironment.reset\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    180\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mreset\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ts\u001B[38;5;241m.\u001B[39mTimeStep:\n\u001B[1;32m    181\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Starts a new sequence and returns the first `TimeStep` of this sequence.\u001B[39;00m\n\u001B[1;32m    182\u001B[0m \n\u001B[1;32m    183\u001B[0m \u001B[38;5;124;03m  Note: Subclasses cannot override this directly. Subclasses implement\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    193\u001B[0m \u001B[38;5;124;03m        corresponding to `observation_spec()`.\u001B[39;00m\n\u001B[1;32m    194\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m--> 195\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_current_time_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reset\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    196\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_current_time_step\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/tf_agents/environments/gym_wrapper.py:199\u001B[0m, in \u001B[0;36mGymWrapper._reset\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_done \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_match_obs_space_dtype:\n\u001B[0;32m--> 199\u001B[0m   observation \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_to_obs_space_dtype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobservation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    200\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ts\u001B[38;5;241m.\u001B[39mrestart(observation)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/tf_agents/environments/gym_wrapper.py:242\u001B[0m, in \u001B[0;36mGymWrapper._to_obs_space_dtype\u001B[0;34m(self, observation)\u001B[0m\n\u001B[1;32m    227\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Make sure observation matches the specified space.\u001B[39;00m\n\u001B[1;32m    228\u001B[0m \n\u001B[1;32m    229\u001B[0m \u001B[38;5;124;03mObservation spaces in gym didn't have a dtype for a long time. Now that they\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    239\u001B[0m \u001B[38;5;124;03m  The observation with a dtype matching the observation spec.\u001B[39;00m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    241\u001B[0m \u001B[38;5;66;03m# Make sure we handle cases where observations are provided as a list.\u001B[39;00m\n\u001B[0;32m--> 242\u001B[0m flat_obs \u001B[38;5;241m=\u001B[39m \u001B[43mnest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflatten_up_to\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_observation_spec\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobservation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    244\u001B[0m matched_observations \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    245\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m spec, obs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flat_obs_spec, flat_obs):\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/util/nest.py:1247\u001B[0m, in \u001B[0;36mflatten_up_to\u001B[0;34m(shallow_tree, input_tree, check_types, expand_composites)\u001B[0m\n\u001B[1;32m   1170\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Flattens `input_tree` up to `shallow_tree`.\u001B[39;00m\n\u001B[1;32m   1171\u001B[0m \n\u001B[1;32m   1172\u001B[0m \u001B[38;5;124;03mRefer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1244\u001B[0m \u001B[38;5;124;03m    `input_tree`.\u001B[39;00m\n\u001B[1;32m   1245\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1246\u001B[0m is_nested_fn \u001B[38;5;241m=\u001B[39m _is_nested_or_composite \u001B[38;5;28;01mif\u001B[39;00m expand_composites \u001B[38;5;28;01melse\u001B[39;00m _is_nested\n\u001B[0;32m-> 1247\u001B[0m \u001B[43massert_shallow_structure\u001B[49m\u001B[43m(\u001B[49m\u001B[43mshallow_tree\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1248\u001B[0m \u001B[43m                         \u001B[49m\u001B[43minput_tree\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1249\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mcheck_types\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheck_types\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1250\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mexpand_composites\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexpand_composites\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1251\u001B[0m \u001B[38;5;66;03m# Discard paths returned by _yield_flat_up_to.\u001B[39;00m\n\u001B[1;32m   1252\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[1;32m   1253\u001B[0m     v \u001B[38;5;28;01mfor\u001B[39;00m _, v \u001B[38;5;129;01min\u001B[39;00m _yield_flat_up_to(shallow_tree, input_tree, is_nested_fn)\n\u001B[1;32m   1254\u001B[0m ]\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/util/nest.py:1078\u001B[0m, in \u001B[0;36massert_shallow_structure\u001B[0;34m(shallow_tree, input_tree, check_types, expand_composites)\u001B[0m\n\u001B[1;32m   1076\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_nested_fn(shallow_tree):\n\u001B[1;32m   1077\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_nested_fn(input_tree):\n\u001B[0;32m-> 1078\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m   1079\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIf shallow structure is a sequence, input must also be a sequence. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1080\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInput has type: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mtype\u001B[39m(input_tree))\n\u001B[1;32m   1082\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(shallow_tree, _wrapt\u001B[38;5;241m.\u001B[39mObjectProxy):\n\u001B[1;32m   1083\u001B[0m     shallow_type \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtype\u001B[39m(shallow_tree\u001B[38;5;241m.\u001B[39m__wrapped__)\n",
      "\u001B[0;31mTypeError\u001B[0m: If shallow structure is a sequence, input must also be a sequence. Input has type: <class 'int'>."
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "PIL.Image.fromarray(env.render())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T00:33:23.329587Z",
     "start_time": "2023-07-13T00:33:23.290310Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Spec:\n",
      "(BoundedArraySpec(shape=(), dtype=dtype('int64'), name='observation/tuple_0', minimum=0, maximum=31), BoundedArraySpec(shape=(), dtype=dtype('int64'), name='observation/tuple_1', minimum=0, maximum=10), BoundedArraySpec(shape=(), dtype=dtype('int64'), name='observation/tuple_2', minimum=0, maximum=1))\n"
     ]
    }
   ],
   "source": [
    "print('Observation Spec:')\n",
    "print(env.time_step_spec().observation)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T00:27:18.279211Z",
     "start_time": "2023-07-13T00:27:18.132121Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward Spec:\n",
      "ArraySpec(shape=(), dtype=dtype('float32'), name='reward')\n"
     ]
    }
   ],
   "source": [
    "print('Reward Spec:')\n",
    "print(env.time_step_spec().reward)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T00:27:18.279257Z",
     "start_time": "2023-07-13T00:27:18.132241Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Spec:\n",
      "BoundedArraySpec(shape=(), dtype=dtype('int64'), name='action', minimum=0, maximum=1)\n"
     ]
    }
   ],
   "source": [
    "print('Action Spec:')\n",
    "print(env.action_spec())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T00:27:18.279380Z",
     "start_time": "2023-07-13T00:27:18.132279Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step:\n",
      "TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': (array(10), array(10), array(0)),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(0, dtype=int32)})\n",
      "Next time step:\n",
      "TimeStep(\n",
      "{'discount': array(1., dtype=float32),\n",
      " 'observation': (array(17), array(10), array(0)),\n",
      " 'reward': array(0., dtype=float32),\n",
      " 'step_type': array(1, dtype=int32)})\n"
     ]
    }
   ],
   "source": [
    "time_step = env.reset()\n",
    "print('Time step:')\n",
    "print(time_step)\n",
    "\n",
    "action = np.array(1, dtype=np.int32)\n",
    "\n",
    "next_time_step = env.step(action)\n",
    "print('Next time step:')\n",
    "print(next_time_step)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T00:27:18.279430Z",
     "start_time": "2023-07-13T00:27:18.172469Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "outputs": [],
   "source": [
    "train_py_env = suite_gym.load(env_name)\n",
    "eval_py_env = suite_gym.load(env_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T00:27:18.279457Z",
     "start_time": "2023-07-13T00:27:18.172558Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "outputs": [],
   "source": [
    "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T00:27:18.279487Z",
     "start_time": "2023-07-13T00:27:18.172589Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Agent"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action tensor spec: BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0), maximum=array(1))\n",
      "\n",
      "num actions 2\n",
      "\n",
      "input None\n",
      "layer 0 input_19\n",
      "layer 1 dense_178\n",
      "layer 2 dense_179\n"
     ]
    }
   ],
   "source": [
    "fc_layer_params = (100, 50)\n",
    "action_tensor_spec = tensor_spec.from_spec(env.action_spec())\n",
    "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
    "print(f\"action tensor spec: {action_tensor_spec}\\n\")\n",
    "print(f\"num actions {num_actions}\\n\")\n",
    "\n",
    "\n",
    "# Define a helper function to create Dense layers configured with the right\n",
    "# activation and kernel initializer.\n",
    "def dense_layer(num_units):\n",
    "    return tf.keras.layers.Dense(\n",
    "        num_units,\n",
    "        activation=tf.keras.activations.relu,\n",
    "        kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
    "            scale=2.0, mode='fan_in', distribution='truncated_normal'\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# QNetwork consists of a sequence of Dense layers followed by a dense layer\n",
    "# with `num_actions` units to generate one q_value per available action as\n",
    "# its output.\n",
    "dense_layers = [dense_layer(num_units) for num_units in fc_layer_params]\n",
    "input_layer = tf.keras.layers.InputLayer(input_shape=(3,))\n",
    "q_values_layer = tf.keras.layers.Dense(\n",
    "    num_actions,\n",
    "    activation=None,\n",
    "    kernel_initializer=tf.keras.initializers.RandomUniform(\n",
    "        minval=-0.03, maxval=0.03\n",
    "    ),\n",
    "    bias_initializer=tf.keras.initializers.Constant(-0.2)\n",
    ")\n",
    "q_net = sequential.Sequential(\n",
    "    [input_layer] + dense_layers + [q_values_layer],\n",
    "    input_spec=env.observation_spec()\n",
    ")\n",
    "print(f\"input {q_net.input_spec}\")\n",
    "print(f\"layer 0 {q_net.layers[0].name}\")\n",
    "print(f\"layer 1 {q_net.layers[1].name}\")\n",
    "print(f\"layer 2 {q_net.layers[2].name}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T00:27:18.348165Z",
     "start_time": "2023-07-13T00:27:18.175746Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'sequential_57' (type Sequential).\n\nLayer \"dense_178\" expects 1 input(s), but it received 3 input tensors. Inputs received: [<tf.Tensor: shape=(1,), dtype=int64, numpy=array([7])>, <tf.Tensor: shape=(1,), dtype=int64, numpy=array([8])>, <tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>]\n\nCall arguments received by layer 'sequential_57' (type Sequential):\n  • inputs=('tf.Tensor(shape=(1,), dtype=int64)', 'tf.Tensor(shape=(1,), dtype=int64)', 'tf.Tensor(shape=(1,), dtype=int64)')\n  • network_state=()\n  • kwargs={'step_type': 'tf.Tensor(shape=(1,), dtype=int32)', 'training': 'None'}\n  In call to configurable 'DqnAgent' (<class 'tf_agents.agents.dqn.dqn_agent.DqnAgent'>)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[320], line 16\u001B[0m\n\u001B[1;32m      3\u001B[0m train_step_counter \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mVariable(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# agent = ppo_agent.PPOAgent(\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m#     train_env.time_step_spec(),\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m#     train_env.action_spec(),\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m#     gamma=1,  # discount factor\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# )\u001B[39;00m\n\u001B[0;32m---> 16\u001B[0m agent \u001B[38;5;241m=\u001B[39m \u001B[43mdqn_agent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDqnAgent\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_env\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtime_step_spec\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_env\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maction_spec\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43mq_network\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mq_net\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtd_errors_loss_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcommon\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43melement_wise_squared_loss\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_step_counter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_step_counter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtarget_update_tau\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# soft updates\u001B[39;49;00m\n\u001B[1;32m     24\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgamma\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# discount factor\u001B[39;49;00m\n\u001B[1;32m     25\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     27\u001B[0m agent\u001B[38;5;241m.\u001B[39minitialize()\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/gin/config.py:1605\u001B[0m, in \u001B[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1603\u001B[0m scope_info \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m in scope \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(scope_str) \u001B[38;5;28;01mif\u001B[39;00m scope_str \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m   1604\u001B[0m err_str \u001B[38;5;241m=\u001B[39m err_str\u001B[38;5;241m.\u001B[39mformat(name, fn_or_cls, scope_info)\n\u001B[0;32m-> 1605\u001B[0m \u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maugment_exception_message_and_reraise\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merr_str\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/gin/utils.py:41\u001B[0m, in \u001B[0;36maugment_exception_message_and_reraise\u001B[0;34m(exception, message)\u001B[0m\n\u001B[1;32m     39\u001B[0m proxy \u001B[38;5;241m=\u001B[39m ExceptionProxy()\n\u001B[1;32m     40\u001B[0m ExceptionProxy\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtype\u001B[39m(exception)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\n\u001B[0;32m---> 41\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m proxy\u001B[38;5;241m.\u001B[39mwith_traceback(exception\u001B[38;5;241m.\u001B[39m__traceback__) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/gin/config.py:1582\u001B[0m, in \u001B[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1579\u001B[0m new_kwargs\u001B[38;5;241m.\u001B[39mupdate(kwargs)\n\u001B[1;32m   1581\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1582\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mnew_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mnew_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1583\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m   1584\u001B[0m   err_str \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/tf_agents/agents/dqn/dqn_agent.py:239\u001B[0m, in \u001B[0;36mDqnAgent.__init__\u001B[0;34m(self, time_step_spec, action_spec, q_network, optimizer, observation_and_action_constraint_splitter, epsilon_greedy, n_step_update, boltzmann_temperature, emit_log_probability, target_q_network, target_update_tau, target_update_period, td_errors_loss_fn, gamma, reward_scale_factor, gradient_clipping, debug_summaries, summarize_grads_and_vars, train_step_counter, training_data_spec, name)\u001B[0m\n\u001B[1;32m    236\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m observation_and_action_constraint_splitter:\n\u001B[1;32m    237\u001B[0m   net_observation_spec, _ \u001B[38;5;241m=\u001B[39m observation_and_action_constraint_splitter(\n\u001B[1;32m    238\u001B[0m       net_observation_spec)\n\u001B[0;32m--> 239\u001B[0m \u001B[43mq_network\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_variables\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnet_observation_spec\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m target_q_network:\n\u001B[1;32m    241\u001B[0m   target_q_network\u001B[38;5;241m.\u001B[39mcreate_variables(net_observation_spec)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/tf_agents/networks/network.py:221\u001B[0m, in \u001B[0;36mNetwork.create_variables\u001B[0;34m(self, input_tensor_spec, **kwargs)\u001B[0m\n\u001B[1;32m    219\u001B[0m initial_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_initial_state(batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    220\u001B[0m step_type \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mfill((\u001B[38;5;241m1\u001B[39m,), time_step\u001B[38;5;241m.\u001B[39mStepType\u001B[38;5;241m.\u001B[39mFIRST)\n\u001B[0;32m--> 221\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    222\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrandom_input\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    223\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstep_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstep_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    224\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnetwork_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitial_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    225\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_calc_unbatched_spec\u001B[39m(x):\n\u001B[1;32m    228\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Build Network output spec by removing previously added batch dimension.\u001B[39;00m\n\u001B[1;32m    229\u001B[0m \n\u001B[1;32m    230\u001B[0m \u001B[38;5;124;03m  Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    233\u001B[0m \u001B[38;5;124;03m    Specs without batch dimension representing x.\u001B[39;00m\n\u001B[1;32m    234\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/tf_agents/networks/network.py:427\u001B[0m, in \u001B[0;36mNetwork.__call__\u001B[0;34m(self, inputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    421\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mis_tensor(network_state)\n\u001B[1;32m    422\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m network_state \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;28;01mNone\u001B[39;00m, ())\n\u001B[1;32m    423\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnetwork_state\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m call_argspec\u001B[38;5;241m.\u001B[39margs\n\u001B[1;32m    424\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m call_argspec\u001B[38;5;241m.\u001B[39mkeywords):\n\u001B[1;32m    425\u001B[0m   normalized_kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnetwork_state\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m--> 427\u001B[0m outputs, new_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mNetwork\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mnormalized_kwargs\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pytype: disable=attribute-error  # typed-keras\u001B[39;00m\n\u001B[1;32m    429\u001B[0m nest_utils\u001B[38;5;241m.\u001B[39massert_matching_dtypes_and_inner_shapes(\n\u001B[1;32m    430\u001B[0m     new_state,\n\u001B[1;32m    431\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate_spec,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    434\u001B[0m     tensors_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`new_state`\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    435\u001B[0m     specs_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`state_spec`\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    437\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m outputs, new_state\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/keras/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m/opt/conda/lib/python3.11/site-packages/tf_agents/networks/sequential.py:224\u001B[0m, in \u001B[0;36mSequential.call\u001B[0;34m(self, inputs, network_state, **kwargs)\u001B[0m\n\u001B[1;32m    221\u001B[0m       stateful_layer_idx \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    222\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    223\u001B[0m       \u001B[38;5;66;03m# Does not maintain state.\u001B[39;00m\n\u001B[0;32m--> 224\u001B[0m       inputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mlayer_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    226\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m inputs, \u001B[38;5;28mtuple\u001B[39m(next_network_state)\n",
      "\u001B[0;31mValueError\u001B[0m: Exception encountered when calling layer 'sequential_57' (type Sequential).\n\nLayer \"dense_178\" expects 1 input(s), but it received 3 input tensors. Inputs received: [<tf.Tensor: shape=(1,), dtype=int64, numpy=array([7])>, <tf.Tensor: shape=(1,), dtype=int64, numpy=array([8])>, <tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>]\n\nCall arguments received by layer 'sequential_57' (type Sequential):\n  • inputs=('tf.Tensor(shape=(1,), dtype=int64)', 'tf.Tensor(shape=(1,), dtype=int64)', 'tf.Tensor(shape=(1,), dtype=int64)')\n  • network_state=()\n  • kwargs={'step_type': 'tf.Tensor(shape=(1,), dtype=int32)', 'training': 'None'}\n  In call to configurable 'DqnAgent' (<class 'tf_agents.agents.dqn.dqn_agent.DqnAgent'>)"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "# agent = ppo_agent.PPOAgent(\n",
    "#     train_env.time_step_spec(),\n",
    "#     train_env.action_spec(),\n",
    "#     q_network=q_net,\n",
    "#     optimizer=optimizer,\n",
    "#     td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "#     train_step_counter=train_step_counter,\n",
    "#     target_update_tau=0.1,  # soft updates\n",
    "#     gamma=1,  # discount factor\n",
    "# )\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter,\n",
    "    target_update_tau=0.1,  # soft updates\n",
    "    gamma=1,  # discount factor\n",
    ")\n",
    "\n",
    "agent.initialize()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T00:27:18.348402Z",
     "start_time": "2023-07-13T00:27:18.217665Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Policies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-13T00:27:18.300682Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "random_policy = random_tf_policy.RandomTFPolicy(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-13T00:27:18.300756Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "example_environment = tf_py_environment.TFPyEnvironment(\n",
    "    suite_gym.load(env_name)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-13T00:27:18.300786Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "time_step = example_environment.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-13T00:27:18.300819Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "random_policy.action(time_step)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-13T00:27:18.300846Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Metrics and Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "    total_return = 0.0\n",
    "    for _ in range(num_episodes):\n",
    "\n",
    "        time_step = environment.reset()\n",
    "        episode_return = 0.0\n",
    "\n",
    "        while not time_step.is_last():\n",
    "            action_step = policy.action(time_step)\n",
    "            time_step = environment.step(action_step.action)\n",
    "            episode_return += time_step.reward\n",
    "        total_return += episode_return\n",
    "\n",
    "    avg_return = total_return / num_episodes\n",
    "    return avg_return.numpy()[0]\n",
    "\n",
    "# See also the metrics module for standard implementations of different metrics.\n",
    "# https://github.com/tensorflow/agents/tree/master/tf_agents/metrics"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-13T00:27:18.300870Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "compute_avg_return(eval_env, random_policy, num_eval_episodes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-13T00:27:18.300893Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Replay Buffer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    agent.collect_data_spec,\n",
    "    batch_size=1,\n",
    "    max_length=replay_buffer_max_length\n",
    ")\n",
    "\n",
    "# rb_observer = replay_buffer.add_batch\n",
    "rb_observer = lambda x: replay_buffer.add_batch(batch_nested_array(x))\n",
    "\n",
    "# rb_observer = reverb_utils.ReverbAddTrajectoryObserver(\n",
    "#   replay_buffer.py_client,\n",
    "#   table_name,\n",
    "#   sequence_length=2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-13T00:27:18.300983Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "agent.collect_data_spec"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-13T00:27:18.301010Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# noinspection PyProtectedMember\n",
    "agent.collect_data_spec._fields"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-13T00:27:18.301034Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Collection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "py_driver.PyDriver(\n",
    "    env,\n",
    "    py_tf_eager_policy.PyTFEagerPolicy(\n",
    "        random_policy, use_tf_function=True),\n",
    "    [rb_observer],\n",
    "    max_steps=initial_collect_steps\n",
    ").run(train_py_env.reset())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-13T00:27:18.301073Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For the curious:\n",
    "# Uncomment to peel one of these off and inspect it.\n",
    "# iter(replay_buffer.as_dataset()).next()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-13T00:27:18.301102Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Dataset generates trajectories with shape [Bx2x...]\n",
    "replayBufferDataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3,\n",
    "    sample_batch_size=batch_size,\n",
    "    num_steps=2\n",
    ").prefetch(3)\n",
    "\n",
    "replayBufferDataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-13T00:27:18.301126Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "replayBufferIterator = iter(replayBufferDataset)\n",
    "print(replayBufferIterator)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-13T00:27:18.301150Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For the curious:\n",
    "# Uncomment to see what the dataset iterator is feeding to the agent.\n",
    "# Compare this representation of replay data\n",
    "# to the collection of individual trajectories shown earlier.\n",
    "\n",
    "# iterator.next()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-13T00:27:18.301169Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the Agent"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "try:\n",
    "    %%time\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "agent.train = common.function(agent.train)\n",
    "\n",
    "# Reset the train step.\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "\n",
    "# Reset the environment.\n",
    "time_step = train_py_env.reset()\n",
    "\n",
    "# Create a driver to collect experience.\n",
    "collect_driver = py_driver.PyDriver(\n",
    "    env,\n",
    "    py_tf_eager_policy.PyTFEagerPolicy(\n",
    "        agent.collect_policy, use_tf_function=True),\n",
    "    [rb_observer],\n",
    "    max_steps=collect_steps_per_iteration)\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "\n",
    "    # Collect a few steps and save to the replay buffer.\n",
    "    time_step, _ = collect_driver.run(time_step)\n",
    "\n",
    "    # Sample a batch of data from the buffer and update the agent's network.\n",
    "    experience, unused_info = next(replayBufferIterator)\n",
    "    train_loss = agent.train(experience).loss\n",
    "\n",
    "    step = agent.train_step_counter.numpy()\n",
    "\n",
    "    if step % log_interval == 0:\n",
    "        print('step = {0}: loss = {1}'.format(step, train_loss))\n",
    "\n",
    "    if step % eval_interval == 0:\n",
    "        avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "        print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "        returns.append(avg_return)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-13T00:27:18.301223Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "iterations = range(0, num_iterations + 1, eval_interval)\n",
    "plt.plot(iterations, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylim(top=250)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-13T00:27:18.301246Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def embed_mp4(filename):\n",
    "    \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
    "    video = open(filename, 'rb').read()\n",
    "    b64 = base64.b64encode(video)\n",
    "    tag = '''\n",
    "  <video width=\"640\" height=\"480\" controls>\n",
    "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "  </video>'''.format(b64.decode())\n",
    "\n",
    "    return IPython.display.HTML(tag)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-13T00:27:18.301268Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_policy_eval_video(policy, filename, num_episodes=5, fps=30):\n",
    "    filename = filename + \".mp4\"\n",
    "    with imageio.get_writer(filename, fps=fps) as video:\n",
    "        for _ in range(num_episodes):\n",
    "            time_step = eval_env.reset()\n",
    "            video.append_data(eval_py_env.render())\n",
    "            while not time_step.is_last():\n",
    "                action_step = policy.action(time_step)\n",
    "                time_step = eval_env.step(action_step.action)\n",
    "                video.append_data(eval_py_env.render())\n",
    "    return embed_mp4(filename)\n",
    "\n",
    "\n",
    "create_policy_eval_video(agent.policy, \"trained-agent\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-13T00:27:18.301289Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "create_policy_eval_video(random_policy, \"random-agent\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-13T00:27:18.301311Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-13T00:27:18.301338Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
